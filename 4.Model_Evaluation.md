对于degree的确定，是我们对于模型的选择（Model Selection），正如我们在线性回归中确定$\theta$一样。在线性回归中，我们通过训练集确定模型，测试集来评估模型的泛化能力。在多项式回归中，我们通过训练集获得了参数$\theta$ ，而通过测试集确定了模型，那么，这两个集合用完了，我们就缺少评估模型泛化能力的数据集。鉴于此，引入了交叉验证集（Cross Validation Set），“交叉”二字体现了一种承上启下的关系，他通过训练集获得的结果，选择了模型，并将该模型交给测试集进行评估：
- 训练集：60%，确定参数$\theta$
- 交叉验证集：20%，进行模型选择。
- 测试集：20%，评价模型预测能力。

## 多项式回归中偏差与方差
![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88.jpg)

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92%E7%9A%84%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE.png)

- 如果多项式次数较高，则容易造成过拟合，此时训练误差很低，但是对于新数据的泛化能力较差，导致交叉验证集和测试集的误差都很高，此时模型出现了高方差：
$$ J_{train}(\theta) is small$$

$$J_{cv}(\theta) >> J_{test}(\theta)$$

- 而当次数较低时，又易出现欠拟合的状况，此时无论是训练集，交叉验证集，还是测试集，都会有很高的误差，此时模型出现了高偏差：
$$ J_{train}(\theta) is large$$
$$ J_{cv}(\theta) \approx J_{train}(\theta)$$


## 正则化过程的偏差与方差
正则化（Regularization）能帮我们解决过拟合问题， λ取值越大，对参数θ的惩罚力度就越大，能够帮助解决过拟合问题，但是，如果惩罚过重，也会造成欠拟合问题，即会出现高偏差。如果λ取值较小，则意味着没有惩罚θ，也就不能解决过拟合问题，会出校高方差：
![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E6%AD%A3%E8%A7%84%E5%8C%96%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88.jpg)

下图反映了正规化过程中，训练集、交叉验证集误差随λ变化的曲线：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E6%AD%A3%E8%A7%84%E5%8C%96%E7%9A%84%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE.png)


## 样本数目对与偏差方差的影响
当训练样本的数目m较小时，意味着可供学习的知识较少，则模型在训练阶段不容易犯错误（训练集误差极低），但也发现不了数据的规律（交叉验证集误差极高）；而当样本数目增多时，意味着需要学习的知识增多，则模型虽然在训练阶段容易犯一些错（训练集误差开始增高），但也更容易探测出数据规律（交叉验证集误差降低）：
![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E6%A0%B7%E6%9C%AC%E6%95%B0%E7%9B%AE.jpg)

- 如果模型出现了高偏差，即出现了欠拟合，学习曲线随样本数目的变化曲线如下图所示，即增加样本数目，仍无法显著降低交叉验证集误差，即无法提高模型的泛化能力：
![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E6%A0%B7%E6%9C%AC%E6%95%B0%E7%9B%AE%E9%AB%98%E5%81%8F%E5%B7%AE.jpg)

- 如果模型出现了高方差，即出现了过拟合，学习曲线随着样本数目变化的曲线如下图所示，即增加样本数目，可以显著降低交叉验证集的误差，提高模型的泛化能力：
![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E6%A0%B7%E6%9C%AC%E6%95%B0%E7%9B%AE%E9%AB%98%E6%96%B9%E5%B7%AE.png)

## 神经网络结构对偏差方差的影响
- 当神经网络的结构简单时，则易出现高偏差，computationally cheaper：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E7%AE%80%E5%8D%95%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png)

- 当神经网络的结构过于复杂时，则易出现高方差，computationally expensive，此时可以通过增大$\lambda$来解决：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/attachments/%E5%A4%8D%E6%9D%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png)

通过改变neural network的的layer和hidden units，不断增加，来看什么时候$J(\theta)$最小

# 总结
|手段|使用场景|
|---|---|
|Get more training examples采集更多的样本|fixed high variance|
|Try smaller sets of features降低特征维度|fixed high variance|
|Try getting additional features采集更多的特征|fixed high bias|
|Try adding polynomial features进行高次多项式回归($x_1^2,x_2^2,x_1,x_2$,etc)|fixed high bias|
|降低参数$\lambda$|fixed high bias|
|增大参数$\lambda$|fixed high variance|


# Machine learning system design
- Collect lots of data 尽可能的扩大数据样本：[Honypot]('https://www.honeynet.org/') 做了这样一件事，把自己包装成一个对黑客极具吸引力的机器，来诱使黑客进行攻击，就像蜜罐（honey pot）吸引密封那样，从而记录攻击行为和手段。
- Develop sophisticated features based on email routing information (from email header)添加更多特征：例如我们可以增加邮件的发送者邮箱作为特征，可以增加标点符号作为特征（垃圾邮件总会充斥了？，！等吸引眼球的标点）。
- Develop sophisticated algorithm to detect misspellings (e.g.
m0rtgage, med1cine, w4tches.)因此，我们就要有手段来识别这些错误拼写，从而优化我们输入到逻辑回归中的样本。

## Error Analysis
对于机器学习问题，吴恩达给出了一些 tips：

- 在一开始，尽量不要将问题复杂化（不要提前优化），先快速实现一个简单算法，然后通过交叉验证集评估模型。这就好比在软件工程中，不会做提前优化，而是先迭代功能。
- 通过绘制学习曲线（learning curve），确定面临的问题是高偏差还是高方差，来决定是添加更多训练样本，还是添加更多特征。
- 甚至可以手动检查交叉验证集中误差较大的样本，确定错误的来源和解决策略。

# Skewed Classes
假定我们通过逻辑回归来预测病人是否患有癌症：0: 病人未患癌症; 1: 病人患有癌症. 
令人欣喜的是，测试集的错误率只有1%。别着急高兴，假如我们的测试样本中只有0.5%患有癌症，那么我们何不直接让预测函数为：$$h_\theta(x) = 0$$
即，我们永远预测病人不患病，那么准确率会高达95%。但这可不是一件好事，我们追求高准确率牺牲的是病人的利益。引起这个问题的原因是样本中出现了偏斜(Skewed Classes)，偏斜即倾斜，大量样本倾斜向了某一类型。

## Precision(查准率) & Recall(召回率)
- Precision(针对预测): 
$$Precision = \frac{TruePos}{PredicatedPos} = \frac{TruePos}{TruePos+FalsePos}$$
在上例中，precision描述了：在我们预测患癌的病人中，**确实患了癌症的病人的比例**。想得到提高precision，我们就要降低False Positive的出现的频次，即，我们只有在拥有十足的把握是，才预测一个样本为正样本。

- Recall(针对实际值): 
$$Recall = \frac{TruePos}{ActualPos} = \frac{TruePos}{TruePos+FalseNeg}$$
在上例中，recall描述了：在患癌的病人中，**有多少病人被我们预测到了**。从公式中我们也可以得出，要想提高召回率，我们就要降低假阴性出现的频次，即，尽可能不放过任何可能为正样本的样本。