## 基于内容的推荐系统

| **Movie/User**       | Alice(1) | Bob(2) | Carol(3) | Dave(4) | $x_1$ | $x_2$ |
| -------------------- | -------- | ------ | -------- | ------- | ----- | ----- |
| Love at last         | 5        | 5      | 0        | 0       | 0.9   | 0     |
| Romance for ever     | 5        | ?      | ?        | 0       | 1.0   | 0.01  |
| Cute puppies of love | ?        | 4      | 0        | ?       | 0.99  | 0     |
| Nonstop car chases   | 0        | 0      | 5        | 4       | 0.1   | 1.0   |
| Swords vs. karate    | 0        | 0      | 5        | ?       | 0     | 0.9   |

该网站对于每部电影都给出了两个评价指数，构成了电影的二维特征向量$x$: 
$$
x_1 = 电影的浪漫指数 ~\\
x_2 = 电影的动作指数
$$
假设用户$i$对于每个指数的偏好程度由向量$θ^{(i)}$所衡量，则我们估计该用户对电影$j$ 的打分为：
$$
y^{(i, j)} = (\theta^{(i)})^T x^{(i)}
$$
这就是**基于内容的推荐系统**，我们根据商品内容来判断用户可能对某个商品的偏好程度，本例中，商品内容就是电影具有的一些指数。我们也知道了，推荐系统中两个重要的维度：**人**和**物**。

另外，引入$r(i,j)$表示第$i$个用户是否对第$j$部电影进行了打分：
$$
r(i,j) =
\begin{cases}
1, \mbox{用户 $i$ 对电影 $j$ 打过分} \\
0, \mbox{otherwise}
\end{cases}
$$

### 目标优化

为了对用户$j$打分状况作出最精确的预测，我们需要：
$$
\min_{\theta^{(j)}} = \frac{1}{2} \sum_{i:r(i,j)=1} \left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2
+ \frac{\lambda}{2} \sum_{k=1}^n (\theta_k^{(j)})^2
$$
那么对于所用用户$1,2,...,n_u$，我们就需要：
$$
\min_{\theta^{(1)}, \theta^{(2)}, ..., \theta^{(n_u)}} = \frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} \left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2
+ \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2
$$
代价函数$J(theta^{(1)}, \theta^{(2)}, ..., \theta^{(n_u)})$ 就为：
$$
J(\theta^{(1)}, \theta^{(2)}, ..., \theta^{(n_u)}) = \frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} \left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2
+ \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2
$$

### 参数更新

我们使用梯度下降法来更新参数：
$$
\begin{align*}
& \mbox{更新偏置（插值）：} \\
& \quad \theta_0^{(j)} = \theta_0^{(j)} - \alpha\sum_{i:r(i,j)=1}\big((\theta^{(j)})^T x^{(i)} - y^{(i,j)}\big) x_0^{(i)} \\
& \mbox{更新权重：} \\
& \quad \theta_k^{(j)} = \theta_k^{(j)} - \alpha\left(\sum_{i:r(i,j)=1}\big((\theta^{(j)})^T x^{(i)} - y^{(i,j)}\big) x_k^{(i)} + \lambda\theta_k^{(j)}\right), \quad k \neq 0
\end{align*}
$$

## 协同过滤（Collaborative Filtering）

回到上一节的问题，每部电影，我们都有评价其内容的特征向量$x$：

| Movie/User           | Alice(1) | Bob(2) | Carol(3) | Dave(4) | $x_1$ | $x_2$ |
| :------------------- | :------- | :----- | :------- | :------ | :---- | :---- |
| Love at last         | 5        | 5      | 0        | 0       | 0.9   | 0     |
| Romance for ever     | 5        | ?      | ?        | 0       | 1.0   | 0.01  |
| Cute puppies of love | ?        | 4      | 0        | ?       | 0.99  | 0     |
| Nonstop car chases   | 0        | 0      | 5        | 4       | 0.1   | 1.0   |
| Swords vs. karate    | 0        | 0      | 5        | ?       | 0     | 0.9   |

但是，在现实中，不会有任何网站，任何人有精力，有能力去评估每部电影所具有的一些指数吧。因此，基于内容的推荐系统从构架初期，可能就会遭遇非常大的阻力。

假定我们先有了各个用户对电影的偏爱评估$\theta$：
$$
\theta^{(1)} = \begin{pmatrix} 0 \\ 5 \\ 0 \end{pmatrix},
\theta^{(2)} = \begin{pmatrix} 0 \\ 5 \\ 0 \end{pmatrix},
\theta^{(3)} = \begin{pmatrix} 0 \\ 0 \\ 5 \end{pmatrix},
\theta^{(4)} = \begin{pmatrix} 0 \\ 5 \\ 0 \end{pmatrix}
$$
并且，不知道电影的指数：

| Movie/User           | Alice(1) | Bob(2) | Carol(3) | Dave(4) | $x_1$ | $x_2$ |
| :------------------- | :------- | :----- | :------- | :------ | :---- | :---- |
| Love at last         | 5        | 5      | 0        | 0       | ?     | ?     |
| Romance for ever     | 5        | ?      | ?        | 0       | ?     | ?     |
| Cute puppies of love | ?        | 4      | 0        | ?       | ?     | ?     |
| Nonstop car chases   | 0        | 0      | 5        | 4       | ?     | ?     |
| Swords vs. karate    | 0        | 0      | 5        | ?       | ?     | ?     |

### 目标优化

现在，我们通过$θ^{(1)},...,θ^{(n_u)}$ 来学习$x(i)$：
$$
\min_{x^{(i)}} = \frac{1}{2} \sum_{j:r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
+ \frac{\lambda}{2} \sum_{k=1}^n (x_k^{(i)})^2
$$
则对于所有的电影指数$x^{(1)},...,x^{(n_m)}$：
$$
\min_{x^{(i)},...,x^{(n_m)}} = \frac{1}{2} \sum_{i=1}^{n_m} \sum_{j:r(i,j)=1}  \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
+ \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2
$$

### 协同过滤算法

现在，我们拥有了评价用户的$\theta$ 和评价**商品**的$x$，并且：

- 给定$\theta$及用户对商品的评价，我们能估计$x$。
- 给定$x$，我们又能估计$\theta$。

因此，就构成了 $\theta$−>$x$−>$\theta$−>$x$...$\theta$−>$x$−>$\theta$−>$x$... 的优化序列，这便构成了协同过滤算法，即同时优化商品和用户具有的参数。

### 协同过滤的目标优化

1. 推测用户喜好：给$x^{(1)}$,...,$x^{(n_m)}$，估计$θ^{(1)}$,...,$θ^{(n_u)}$：
   $$
   \min_{\theta^{(1)}, ..., \theta^{(n_u)}} = \frac{1}{2} \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} \left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2
   + \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2
   $$

2. 推测商品内容：给定$θ^{(1)}$,...,$θ^{(n_u)}$，估计$x^{(1)}$,...,$x^{(n_m)}$：
   $$
   \min_{x^{(i)},...,x^{(n_m)}} = \frac{1}{2} \sum_{i=1}^{n_m} \sum_{j:r(i,j)=1}  \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
   + \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2
   $$

3. 协同过滤：同时优化$x^{(1)}$,...,$x^{(n_m)}$及$θ^{(1)}$,...,$θ^{(n_u)}$：
   $$
   \min J(x^{(i)},...,x^{(n_m)} ; \theta^{(1)}, ..., \theta^{(n_u)})
   $$

亦即：
$$
\min_{x^{(i)},...,x^{(n_m)} ; \theta^{(1)}, ..., \theta^{(n_u)}}
\frac{1}{2} \sum_{(i,j):r(i,j)=1}  \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
+ \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2
+ \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2
$$
$\sum_{(i,j):r(i,j)=1}$ 反映了用户和商品所有有效配对。

### 算法流程

使用了协同过滤的推荐算法流程为：

1. 随机初始化$x^{(1)}$,...,$x^{(n_m)}$; $θ^{(1)}$,...,$θ^{(n_u)}$为一些较小值，与神经网络的参数初始化类似，为避免系统陷入僵死状态，不使用0值初始化。

2. 使用梯度下降法来最小化$J(x^{(i)},...,x^{(n_m)};\theta^{(1)}, ..., \theta^{(n_u)})$, 对于$j=1,2,..,n_u$, $i=1,2,...,n_m$，参数的更新式为：
   $$
   \begin{align*}
   & x_k^{(i)} = x_k^{(i)} - \alpha \left( \sum_{j:r(i,j)=1}\big((\theta^{(j)})^T x^{(i)} - y^{(i,j)}\big) \theta_k^{(j)} + \lambda x_k^{(i)}\right) \\
   
   & \theta_k^{(j)} = \theta_k^{(j)} - \alpha\left(\sum_{i:r(i,j)=1}\big((\theta^{(j)})^T x^{(i)} - y^{(i,j)}\big) x_k^{(i)} + \lambda\theta_k^{(j)} \right)
   \end{align*}
   $$

3. 如果用户的偏好向量为$\theta$，而商品的特征向量为$x$，则可以预测用户评价为$\theta^Tx$。

因为协同过滤算法$\theta$和$x$相互影响，因此，二者都没必要使用偏置$θ_0$和$x_0$，即，$x \in R^n$、$\theta \in R^n$。

### 获得类似电影

当我们获得了电影$i$的特征向量后，我们就可以通过计算$||x^{(j)}-x^{(i)}||$来比较电影$j$与电影$i$的相似度。那么，给予了电影$j$足够好评的用户，也会被推荐到类似的电影。

## 低秩矩阵分解（Low Rank Matrix Factorization）

我们将用户对电影的评分表格：

| Movie/User           | Alice(1) | Bob(2) | Carol(3) | Dave(4) |
| :------------------- | :------- | :----- | :------- | :------ |
| Love at last         | 5        | 5      | 0        | 0       |
| Romance for ever     | 5        | ?      | ?        | 0       |
| Cute puppies of love | ?        | 4      | 0        | ?       |
| Nonstop car chases   | 0        | 0      | 5        | 4       |
| Swords vs. karate    | 0        | 0      | 5        | 0       |

用矩阵表示：
$$
Y =
\begin{bmatrix}
5 & 5 & 0 & 0 \\
5 & ? & ? & 0 \\
? & 4 & 0 & ? \\
0 & 0 & 5 & 4 \\
0 & 0 & 5 & 0
\end{bmatrix}
$$
我们发现，由于用户不会对所有电影都进行打分，所以该矩阵是十分稀疏的。如果我们用预测来描述这个矩阵：
$$
Predicated =
\begin{bmatrix}
(\theta^{(1)})^T x^{(1)} & (\theta^{(2)})^T x^{(1)} & \cdots & (\theta^{(n_u)})^T x^{(1)} \\
(\theta^{(1)})^T x^{(2)} & (\theta^{(2)})^T x^{(2)} & \cdots & (\theta^{(n_u)})^T x^{(2)} \\
\vdots & \vdots & \vdots & \vdots \\
(\theta^{(1)})^T x^{(n_m)} & (\theta^{(2)})^T x^{(n_m)} & \cdots & (\theta^{(n_u)})^T x^{(n_m)}
\end{bmatrix}
$$
令：
$$
X =
\begin{bmatrix}
(x^{(1)})^T \\
(x^{(2)})^T \\
\vdots \\
(x^{(n_m)})^T
\end{bmatrix},

\Theta =
\begin{bmatrix}
(\theta^{(1)})^T \\
(\theta^{(2)})^T \\
\vdots \\
(\theta^{(n_u)})^T
\end{bmatrix}
$$
即$X$的每一行描述了一部电影的内容，$Θ^T$的每一列描述了用户对于电影内容偏好程度，亦即，我们将原来稀疏的矩阵分解为了$X$和$Θ^T$。现在预测可以写为：
$$
Predicated = X \Theta^T
$$
用这个方法求取$X$和$Θ$，获得推荐系统需要的参数，称之为**低秩矩阵分解**，该方法不仅能在编程时直接通过向量化的手法获得参数，还通过矩阵分解节省了内存空间。

## 均值标准化

假定我们现在新注册了一个用户 `Eve(5)`，他还没有对任何电影作出评价：

| Movie/User           | Alice(1) | Bob(2) | Carol(3) | Dave(4) | Eve(5) |
| :------------------- | :------- | :----- | :------- | :------ | :----- |
| Love at last         | 5        | 5      | 0        | 0       | ?      |
| Romance for ever     | 5        | ?      | ?        | 0       | ?      |
| Cute puppies of love | ?        | 4      | 0        | ?       | ?      |
| Nonstop car chases   | 0        | 0      | 5        | 4       | ?      |
| Swords vs. karate    | 0        | 0      | 5        | 0       | ?      |

$$
Y =
\begin{bmatrix}
5 & 5 & 0 & 0 & ?\\
5 & ? & ? & 0 & ?\\
? & 4 & 0 & ? & ?\\
0 & 0 & 5 & 4 & ?\\
0 & 0 & 5 & 0 & ?
\end{bmatrix}
$$

则 `Eve(5)` 对于电影内容的偏好应当为参数$θ^{(5)}$所评估，注意到我们的最小化代价函数过程：
$$
\min_{x^{(i)},...,x^{(n_m)} ; \theta^{(1)}, ..., \theta^{(n_u)}}
\frac{1}{2} \sum_{(i,j):r(i,j)=1}  \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)}\right) ^2
+ \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n (x_k^{(i)})^2
+ \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2
$$
由于该用户没有对任何电影作出评价，$θ^{(5)}$能影响上式的项只有：
$$
\frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2
$$
为了最小化该式，我们只能令$\theta^{(5)} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}$，从而，`Eve(5)` 对任何电影的评价将会被预测为：
$$
y(i, 5) = (\theta^{(5)})^T x^{(i)}= 0
$$
显然，这就是一种“不负责任”的预测了，系统会因此认为 `Eve` 对任何电影都不感冒，那么，`Eve` 就是吃饱了撑的来注册这个网站。

为了这个解决这个问题，我们会先求取各个电影的平均得分$μ$：
$$
\mu =
\begin{pmatrix}
2.5 \\
2.5 \\
2 \\
2.25 \\
1.25
\end{pmatrix}
$$
并求取$Y-\mu$，对$Y$进行均值标准化：
$$
Y - \mu =
\begin{bmatrix}
2.5 & 2.5 & -2.5 & -2.5 & ? \\
2.5 & ? & ? & -2.5 & ? \\
? & -2 & -2 & ? & ? \\
-2.25 & -2.25 & 2.75 & 1.75 & ? \\
-1.25 & -1.25 & 3.75 & -1.25 & ?
\end{bmatrix}
$$
对于用户$j$，他对电影$i$的评分就为：
$$
y(i, j) = (\theta^{(i)})^T x^{(j)} + \mu_i
$$
那么Eve对电影的评分就为：
$$
y(i, 5) = (\theta^{(5)})^T x^{(i)} + \mu_i = \mu_i
$$
即，系统在用户未给出评价时，默认该用户对电影的评价与其他用户的平均评价一致。貌似利用均值标准化让用户的初始评价预测客观了些，但这也是盲目的，不准确的。实际环境中，如果一个电影确实没人被评价过，那么他没有任何理由被推荐给用户。



[程序示例--推荐系统]([https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/codes/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html](https://yoyoyohamapi.gitbooks.io/mit-ml/content/推荐系统/codes/推荐系统.html)) 