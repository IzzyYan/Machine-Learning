## Anomaly Detection(异常检验)
异常检测（Anomaly Detection）是机器学习里面的一个常见应用，机器通过训练，将知道什么样的样本是正常样本，从而具备识别异常样本的能力。

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E6%96%B0%E6%9D%A5%E7%9A%84%E5%BC%82%E5%B8%B8%E6%A0%B7%E6%9C%AC.png)

根据已有数据集构建一个概率模型$p(x)$，如果某一样本被认为是正常样本的概率足够小，它就该被当做是异常：

$$
x=
\begin{cases} 异常样本, \mbox{if $p(x)< \epsilon$} \newline
正常样本, \mbox{otherwise}
\end{cases}
$$


### Gaussian Distribution(高斯分布模型)

异常检测的核心就在于找到一个概率模型，帮助我们知道一个样本落入正常样本中的概率，从而帮助我们区分正常和异常样本。**高斯分布（Gaussian Distribution）**模型就是异常检测算法最常使用的概率分布模型。

#### 定义

$$
X \sim N(\mu,\delta^2)
$$

X服从均值为μ，方差为$\delta^2$的高斯分布（也称正态分布），高斯分布的概率密度函数为：
$$
f(x)=\frac{1}{\sqrt{2\pi}\delta}e^{-\frac{(x-\mu)^2}{2}}
$$
概率模型可以描述为：
$$
p(x; \mu, \delta^2)=\frac{1}{\sqrt{2\pi}\delta}e^{-\frac{(x-\mu)^2}{2}}
$$

#### 参数估计

$$
x_j \sim N(\mu,\delta^2)
$$

根据这有限个样本进行**参数估计**：
$$
\begin{align*}
\mu_j &= \frac{1}{m}\sum\limits_{i=1}^mx_j^{(i)} \\
\delta^2_j &= \frac{1}{m}\sum\limits_{i=1}^m(x_j^{(i)}-\mu_j)^2
\end{align*}
$$
这里对参数$μ$和参数$δ^2$的估计就是二者的[极大似然估计](https://zh.wikipedia.org/wiki/最大似然估计)。

假定有数据集：
$$
{x^{(1)},x^{(2)},\cdots,x^{(m)}}, x \in R^n
$$
并且，各个特征服从于高斯分布：
$$
x_j \sim N(\mu,\delta^2)
$$
我们完成了对于各个特征服从分布的参数估计后，可以得到：
$$
\begin{align*}
p(x) &= p(x_1;\mu_1, \delta^2_1)p(x_2;\mu_2, \delta^2_2) \cdots p(x_n;\mu_n, \delta^2_n) \\
&= \prod\limits_{j=1}^np(x_j;\mu_j,\delta_j^2) \\
&= \prod\limits_{j=1}^n\frac{1}{\sqrt{2\pi}\delta_j}exp(-\frac{(x_j-\mu_j)^2}{2\delta_j^2})
\end{align*}
$$

## 算法流程与评估

### 算法流程

采用了**高斯分布**的异常检测算法流程如下：

1. 选择一些足够反映异常样本的特征$x_j$.

2. 对各个特征进行参数估计：
   $$
   \begin{align*}
   \mu_j &= \frac{1}{m}\sum\limits_{i=1}^mx_j^{(i)} \\
   \delta^2_j &= \frac{1}{m}\sum\limits_{i=1}^m(x_j^{(i)}-\mu)^2
   \end{align*}
   $$

3. 当获得新的样本$x$时，计算$p(x)$：
   $$
   p(x)=\prod\limits_{j=1}^np(x_j;\mu_j,\delta_j^2)=\prod\limits_{j=1}^n\frac{1}{\sqrt{2\pi}\delta_j}exp(-\frac{(x_j-\mu_j)^2}{2\delta_j^2})
   $$
   如果$p(x)<\epsilon$，则认为样本$x$是异常样本。



### 举个例子

假定我们有两个特征$x1$、$x2$，它们都服从于高斯分布，并且通过参数估计，我们知道了分布参数：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%9A%84%E6%A0%97%E5%AD%90.png)

则模型$p(x)$能由如下的热力图反映，热力图越热的地方，是正常样本的概率越高，参数$ϵ$描述了一个截断高度，当概率落到了截断高度以下（下图紫色区域所示），则为异常样本：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%83%AD%E5%8A%9B%E5%9B%BE.png)

将$p(x)$投影到特征$x1$、$x2$所在平面，下图紫色曲线就反映了$ϵ$的投影，它是一条截断曲线，落在截断曲线以外的样本，都会被认为是异常样本：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%83%AD%E5%8A%9B%E5%9B%BE%E6%8A%95%E5%BD%B1.png)

### 数据集划分

假定我们的引擎数据集被标注了是否为异常样本：
$$
y^{(i)}=
\begin{cases}
0, \mbox{如果 $x^{(i)}$ 为正常样本} \\
1, \mbox{otherwise}
\end{cases}
$$
并且，含有正常样本10000个，异常样本20个。那么，我们可以这样划分数据集：

* **训练集**含6000个正常样本。
* **交叉验证集**含2000个正常样本，10个异常样本。
* **测试集**含2000个正常样本，10个异常样本。

### 算法评估

由于异常样本是非常少的，所以整个数据集是非常**偏斜**的，我们不能单纯的用预测准确率(accuracy)来评估算法优劣，因此，可以考虑使用我们在**算法分析与优化**一节中提过的评价手段：

- 真阳性、假阳性、真阴性、假阴性
- 查准率（Precision）与 召回率（Recall）
- $F_1Score$



## Supervised Learning VS Anomaly Deteciton

| **Anomaly Detection**                                        | Supervised Learning                                          |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| 数据非常偏斜，异常样本数目远小于正常样本数目                 | 数据分布均匀                                                 |
| 异常的类型不一，很难根据对现有的异常样本（即正样本）的拟合来判断出异常样本的形态 | 可以根据对正样本的拟合来知道正样本的形态，从而预测新来的样本是否是正样本 |
| 应用场景: 故障检测、某数据中心对于机器设备的监控、制造业判断一个零部件是否异常 | 应用场景：垃圾邮件检测、天气预测（预测雨天、晴天、或是多云天气）、癌症分类 |



## 特征选择

为了构建异常检测模型，我们希望特征能服从高斯分布。但是，我们一开始拿到的特征的分布可能是left skewed或right skewed。因此，可以通过对数操作或者其他操作将其转化为高斯分布。

### Feature Engineering（特征工程）

通过组合现有特征，来产生标识度更明显的特征。



## Multivariate Gaussian distribution(多元高斯分布模型)

在服务器运转监控的问题中，我们获得一个服务器样本$x$，并且，计算了$p(x_1;μ_1,δ_1^2)$及p(x_2;μ_2,δ_2^2)，认为该服务器的CPU负载和内存使用都在正常范围内，也就认为该服务器运转正常：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E5%8D%95%E7%8B%AC%E8%80%83%E8%99%91%E5%88%86%E5%B8%83.png)

但是，截断边界却将该样本截在了正常样本之外，认为服务器发生异常：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E9%94%99%E8%AF%AF%E7%9A%84%E6%88%AA%E6%96%AD.png)

可以看到，出现错误截端的原因在于，我们的高斯分布模型形成的截断边界太固定。试想，如果我们原有的决策边界能经放缩，旋转等操作，变换到下图的紫色边界位置，该服务器就不会被错分为异常了：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E5%B8%8C%E6%9C%9B%E7%9A%84%E6%88%AA%E6%96%AD.png)

为此，引入了多元高斯分布模型。

### 定义

多元高斯分布模型被定义为：
$$
p(x;\mu,\Sigma)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^\frac{1}{2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))
$$
其中，$μ$表示**样本均值**，$Σ$表示**样本协方差矩阵**(covariance matrix)。

多元高斯分布模型的热力图如下：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E7%83%AD%E5%8A%9B%E5%9B%BE.png)

### 参数

* 改变$Σ$**主对角线**的数值可以进行不同方向的宽度拉伸：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E6%94%B9%E5%8F%98%E4%B8%BB%E5%AF%B9%E8%A7%92%E7%BA%BF.png)

* 改变$Σ$**次对角线**的数值可以旋转分布图像：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E6%94%B9%E5%8F%98%E6%AC%A1%E5%AF%B9%E8%A7%92%E7%BA%BF.png)

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E6%94%B9%E5%8F%98%E6%AC%A1%E5%AF%B9%E8%A7%92%E7%BA%BF2.png)

* 改变$μ$可以对分布图像进行位移：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E6%94%B9%E5%8F%98%E5%9D%87%E5%80%BC%E5%90%91%E9%87%8F.png)

### 参数估计

多元高斯分布模型的参数估计如下：
$$
\begin{align*}
\mu &= \frac{1}{m}\sum\limits_{i=1}^mx^{(i)} \\
\Sigma &= \frac{1}{m}\sum\limits_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T
\end{align*}
$$

### 算法流程

采用了**多元高斯分布**的异常检测算法流程如下：

1. 选择一些足够反映异常样本的特征$xj$。

2. 对各个**样本**进行参数估计：
   $$
   \begin{align*}
   \mu &= \frac{1}{m}\sum\limits_{i=1}^mx^{(i)} \\
   \Sigma &= \frac{1}{m}\sum\limits_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T
   \end{align*}
   $$
   

3. 当新的样本$x$到来时，计算$p(x)$：
   $$
   p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^\frac{1}{2}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))
   $$
   如果$p(x)<\epsilon$，则认为样本$x$是异常样本。



## 多元高斯分布模型与一般高斯分布模型的差异

实际上，一般的高斯分布模型只是多元高斯分布模型的一个**约束**，它将多元高斯分布的等高线约束到了如下所示同轴分布（概率密度的等高线是沿着轴向的）：

![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/attachments/%E5%A4%9A%E5%85%83%E9%AB%98%E6%96%AF_%E5%90%8C%E8%BD%B4%E5%88%86%E5%B8%83.png)

| Original Model                             | Multivariate Gaussian                                        |
| ------------------------------------------ | ------------------------------------------------------------ |
| 需要手动创建一些特征来描述某些特征的相关性 | 利用协方差矩阵$Σ$获得了各个特征相关性                        |
| 计算复杂度低，适用于高维特征               | 计算复杂                                                     |
| 在样本数目$m$较小时也工作良好              | 需要$Σ$可逆，亦即需要$m>n$，且各个特征不能线性相关，如: 不能存在 $x_2=3x_1$. |

[程序示例-异常检测](https://yoyoyohamapi.gitbooks.io/mit-ml/content/异常检测/codes/异常检测.html)

