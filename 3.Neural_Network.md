If network has $s_j$ units in layer $j$ and $s_{j+1}$ units in layer $j+1$, then $\theta^{j}$ will be of dimension $s_{j+1} * (s_j + 1)$. (+1指的是bias node)

##神经网络实现异或(XOR) 
[关于神经网络的基础知识以及前向传播](URL 'https://www.cnblogs.com/python27/p/MachineLearningWeek04.html')
[Neural Network Quiz](URL 'https://github.com/mGalarnyk/datasciencecoursera/blob/master/Stanford_Machine_Learning/Week4/week3quiz1.md')