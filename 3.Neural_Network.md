Training a Neural Network

1. Randomly initialize the weights
2. Implement forward propagation to get $h_\Theta(x^{(i)})$ for any $x^{(i)}$
 
3. Implement the cost function
4. Implement backpropagation to compute partial derivatives
5. Use gradient checking to confirm that your backpropagation works. Then disable gradient checking.
6. Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta.

Ideally, you want $h_\Theta(x^{(i)}) \approx y^{(i)}$. This will minimize our cost function. However, keep in mind that $J(\Theta)$ is not convex and thus we can end up in a local minimum instead.

总逻辑：先通过FP得到每个layer的激活值(activation)，再通过BP调整每个layer的$\theta$以减小代价函数，循环来找到local minumum。

If network has $s_j$ units in layer $j$ and $s_{j+1}$ units in layer $j+1$, then $\theta^{j}$ will be of dimension $s_{j+1} * (s_j + 1)$. (+1指的是bias node)

## 前向传播(Forward Propagation):
神经网络实现异或(XOR) 

[关于神经网络的基础知识以及前向传播](https://www.cnblogs.com/python27/p/MachineLearningWeek04.html)

[Neural Network Quiz](https://github.com/mGalarnyk/datasciencecoursera/blob/master/Stanford_Machine_Learning/Week4/week3quiz1.md')

## 反向传播(Back Propagation):
[公式推导](https://www.cnblogs.com/python27/p/MachineLearningWeek05.html) (用Chain Rule)

## 代价函数(Cost Function)
令：L = 神经网络总共包含的层数，$s_l$ = 第l层的神经元数目，K = 输出层的神经元数，即分类的数目
神经网络的层与层之间都可以看做构成了一个多个逻辑回归问题（根据神经元的数量），因此，其代价函数与逻辑回归的代价函数类似，其中K代表类别，l表示层级，并且考虑了正规化：

$$J(\Theta) = - \frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[y^{(i)}_k \log ((h_\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\log (1 - (h_\Theta(x^{(i)}))_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} ( \Theta_{j,i}^{(l)})^2$$

矩阵表示为：

$$J(\Theta) = - \frac{1}{m}\sum(Y^{T} .* log(\Theta A)) + log(1-\Theta A).*(1-Y^{T}))$$

## 训练过程
假定有训练集${(x^{(1)}, y^{(1)}),...,(x^{(m)},y^{(m)})}$，使用了反向传播的神经网络训练过程如下：
1. for all l,i,j, 初始化权值梯度$\Delta^{(l)}$: 
   
   $$\Delta_{ij}^{(l)} = 0$$

2. for $i = 1$ to $m$: 
    令$a^{1} = x^{i}$
    执行Forward Propagation，计算各层的激活向量: $a^{l}$
    通过标签向量$y^{i}$, 计算出层的误差向量: $\delta^{(L)} = a^{(L)} - y^{(i)}$
    反向依次计算其他层误差向量: $\delta^{(L-1)},\delta^{(L-2)},...,\delta^{(2)}$
    求$\Delta_{ij}^{(l)} = a_j^{(l)}\delta_i^{(l+1)}$，即：
    $$\Delta^{(l)} = \delta^{(l+1)}(a^{(l)})^T$$

3. 求各层weight的更新增量$D^{(l)}$，连接bias的weight不进行正则化：
    $D^{(l)}_{i,j} = \dfrac{1}{m}(\Delta^{(l)}_{i,j} + \lambda\Theta^{(l)}_{i,j})$ if j != 0
    
    $D^{(l)}_{i,j} =\frac{1}{m}\Delta_{ij}^{(l)}$ if j = 0

4. 更新各层的权值矩阵$\Theta^{(l)}$, 其中$\alpha$为学习率: 
   
   $$\Theta^{(l)} = \Theta^{(l)} + \alpha D^{(l)}$$


## 参数展开(Unrolling Parameters)
Cost Function只支持传递向量作为参数，因此，需要先将矩阵元素平铺开为一个长向量：
python中展开：
```python
import numpy as np

thetaVector = np.r_[Theta1.reshape(-1,1), Theta2.reshape(-1,1), Theta3.reshape(-1,1)]
deltaVector = np.r_[ D1.reshape(-1,1), D2.reshape(-1,1), D3.reshape(-1,1) ]
```
python中还原：
```python
import numpy as np

Theta1 = thetaVec[0:110].reshape(10,11)
Theta2 = thetaVec[110:220].reshape(10,11)
Theta3 = thetaVec[220:231].reshape(1,11)
```

## 梯度校验(Gradient Checking)
直接使用BP算法可能会出现许多bug，因此，需要使用梯度校验（Gradient Checking）的手段。
![avatar](https://i.loli.net/2018/12/02/5c03d7c2cb557.png)

$$\frac{d}{d\Theta}J(\Theta) \approx \frac{J(\Theta+\epsilon)-J(\Theta-\epsilon)}{2\epsilon}$$
- 通常，$\epsilon$取较小值，如0.0001

包含有梯度校验的BP算法如下：
1. 首先由反向传播算法获得展开的$DVec$: 
   $DVec = [D^{(1)},D^{(2)},D^{(3)},...D^{(n)}]$
2. 计算梯度近似$gradApprox$，$\theta_j$是$\Theta^{j}$的展开: 
   
   $\dfrac{\partial}{\partial\theta_j}J(\theta) \approx \dfrac{J(\theta_1, \dots, \theta_j + \epsilon, \dots, \theta_n) - J(\theta_1, \dots, \theta_j - \epsilon, \dots, \theta_n)}{2\epsilon}$ for j = 1 to n

    $gradApprox = [\dfrac{\partial}{\partial\theta_1}J(\theta), \dfrac{\partial}{\partial\theta_2}J(\theta), ..., \dfrac{\partial}{\partial\theta_n}J(\theta)]$
3. 比较$gradApprox$与$DVec$的相似程度（比如可以用欧几里得距离）：
   $$gradApprox \approx DVec$$

如果上式成立，则证明网络中BP算法有效，此时关闭梯度校验算法（因为梯度的近似计算效率很慢），继续网络的训练过程。
如果最终找到的local minimum，也是可以接受。

## 权值初始化
### 0 值初始化 
在逻辑回归中，我们通常会初始化所有权值为0，假如在如下的神经网络也采用0值初始化：
![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/attachments/0%E5%80%BC%E5%88%9D%E5%A7%8B%E5%8C%96.png)
则可以得到：
$a_1^{(1)} = a_2^{(2)}$
则$\delta_1^{(1)} = \delta_2^{(1)}$
则$\frac{\partial}{\partial \Theta_{01}^{(1)}J(\Theta)}$ = $\frac{\partial}{\partial \Theta_{02}^{(1)}}J(\Theta)$
则更新后的权值：$\Theta_{01}^{(1)}$ = $\Theta_{02}^{(1)}$

亦即，每次迭代，所有权值的数值都一样，这意味着，隐含层的神经元激活值也将一样，也就是无论隐含层层数有多少，各层的神经元有多少，由于各层的神经元激活值大小一样，也就相当于各层只有一个有效神经元（特征），这就失去了神经网络进行特征扩展和优化的本意了。

### 随机初始化 
我们看到了固定值初始化将会是神经网络丧失其特性，因此，对于各层的权值矩阵，采用随机初始化策略。随机值产生的区间我们定义为$[-\epsilon, +\epsilon]$，并假定：

$$\Theta^{(1)} \in R^{10 \times 11}, \Theta^{(2)} \in R^{1 \times 11}$$
在python中，随机初始化权值的代码如下：
```python
import numpy as np

Theta1 = np.random.rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON
Theta2 = np.random.rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON
```

## 神经网络设计

[Python实现](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/codes/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1.html)

## 感知器(Perceptron)
感知器是最简单的神经网络结构，其不包含隐含层(Hidden layer): 
![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/attachments/%E9%80%BB%E8%BE%91AND%E8%BF%90%E7%AE%97%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1.jpg)

数学表达为：
$$\begin{bmatrix}
x_0 \newline x_1 \newline x_2
\end{bmatrix}
\rightarrow
\begin{bmatrix}
a_1^{(2)}
\end{bmatrix}
\rightarrow
h_\theta(x)$$

其输出为：
$$h_\theta(x) = a_1(2) = \Theta^{(1)}a^{(1)} = \Theta^{(1)}x$$

可以看出此预测函数和回归问题类似，实际上回归问题算是感知器的非网络表达形式。