If network has $s_j$ units in layer $j$ and $s_{j+1}$ units in layer $j+1$, then $\theta^{j}$ will be of dimension $s_{j+1} * (s_j + 1)$. (+1指的是bias node)

总逻辑：先通过FP得到每个layer的激活值(activation)，再通过BP调整每个layer的$\theta$以减小代价函数，循环来找到local minumum。

## 前向传播(Forward Probagation):
神经网络实现异或(XOR) 
[关于神经网络的基础知识以及前向传播](URL 'https://www.cnblogs.com/python27/p/MachineLearningWeek04.html')
[Neural Network Quiz](URL 'https://github.com/mGalarnyk/datasciencecoursera/blob/master/Stanford_Machine_Learning/Week4/week3quiz1.md')

## 反向传播(Back Probagation):
[公式推导](URL 'https://www.cnblogs.com/python27/p/MachineLearningWeek05.html') (用Chain Rule)

## 代价函数(Cost Function)
令：L = 神经网络总共包含的层数，$s_l$ = 第l层的神经元数目，K = 输出层的神经元数，即分类的数目
神经网络的层与层之间都可以看做构成了一个多个逻辑回归问题（根据神经元的数量），因此，其代价函数与逻辑回归的代价函数类似，其中K代表类别，l表示层级，并且考虑了正规化：

$J(\Theta) = - \frac{1}{m} \sum_{i=1}^m \sum_{k=1}^K \left[y^{(i)}_k \log ((h_\Theta (x^{(i)}))_k) + (1 - y^{(i)}_k)\log (1 - (h_\Theta(x^{(i)}))_k)\right] + \frac{\lambda}{2m}\sum_{l=1}^{L-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_{l+1}} ( \Theta_{j,i}^{(l)})^2$

矩阵表示为：
$J(\Theta) = - \frac{1}{m}\sum(Y^{T} .* log(\Theta A)) + log(1-\Theta A).*(1-Y^{T}))$

## 训练过程
假定有训练集${(x^{(1)}, y^{(1)}),...,(x^{(m)},y^{(m)})}$，使用了反向传播的神经网络训练过程如下：
1. for all l,i,j, 初始化权值梯度$\Delta^{(l)}$: 
   $\Delta_{ij}^{(l)} = 0$

2. for $i = 1$ to $m$: 
    令$a^{1} = x^{i}$
    执行Forward Probagation，计算各层的激活向量: $a^{l}$
    通过标签向量$y^{i}$, 计算出层的误差向量: $\delta^{(L)} = a^{(L)} - y^{(i)}$
    反向依次计算其他层误差向量: $\delta^{(L-1)},\delta^{(L-2)},...,\delta^{(2)}$
    求$\Delta_{ij}^{(l)} = a_j^{(l)}\delta_i^{(l+1)}$，即：$\Delta^{(l)} = \delta^{(l+1)}(a^{(l)})^T$

3. 求各层weight的更新增量$D^{(l)}$，连接bias的weight不进行正则化：
    $D^{(l)}_{i,j} =
\dfrac{1}{m}(\Delta^{(l)}_{i,j} + \lambda\Theta^{(l)}_{i,j})$ if j != 0
$D^{(l)}_{i,j} =\frac{1}{m}\Delta_{ij}^{(l)}$ if j = 0

4. 更新各层的权值矩阵$\Theta^{(l)}$, 其中$\alpha$为学习率: 
   $\Theta^{(l)} = \Theta^{(l)} + \alpha D^{(l)}$


## 参数展开(Unrolling Parameters)
Cost Function只支持传递向量作为参数，因此，需要先将矩阵元素平铺开为一个长向量：
python中展开：
```python
import numpy as np

thetaVector = np.r_[Theta1.reshape(-1,1), Theta2.reshape(-1,1), Theta3.reshape(-1,1)]
deltaVector = np.r_[ D1.reshape(-1,1), D2.reshape(-1,1), D3.reshape(-1,1) ]
```
python中还原：
```python
import numpy as np

Theta1 = thetaVec[0:110].reshape(10,11)
Theta2 = thetaVec[110:220].reshape(10,11)
Theta3 = thetaVec[220:231].reshape(1,11)
```

## 梯度校验(Gradient Checking)
直接使用BP算法可能会出现许多bug，因此，需要使用梯度校验（Gradient Checking）的手段。
![avatar](https://i.loli.net/2018/12/02/5c03d7c2cb557.png)
$\frac{d}{d\Theta}J(\Theta) \approx \frac{J(\Theta+\epsilon)-J(\Theta-\epsilon)}{2\epsilon}$
- 通常，$\epsilon$取较小值，如0.01

包含有梯度校验的BP算法如下：
1. 首先由反向传播算法获得展开的$DVec$: 
   $DVec = [D^{(1)},D^{(2)},D^{(3)},...D^{(n)}]$
2. 计算梯度近似$gradApprox$，$\theta_j$是$\Theta^{j}$的展开: 
   $\dfrac{\partial}{\partial\theta_j}J(\theta) \approx \dfrac{J(\theta_1, \dots, \theta_j + \epsilon, \dots, \theta_n) - J(\theta_1, \dots, \theta_j - \epsilon, \dots, \theta_n)}{2\epsilon}$ for j = 1 to n

    $gradApprox = [\dfrac{\partial}{\partial\theta_1}J(\theta), \dfrac{\partial}{\partial\theta_2}J(\theta), ..., \dfrac{\partial}{\partial\theta_n}J(\theta)]$
3. 比较$gradApprox$与$DVec$的相似程度（比如可以用欧几里得距离）：
   $gradApprox \approx DVec$

如果上式成立，则证明网络中BP算法有效，此时关闭梯度校验算法（因为梯度的近似计算效率很慢），继续网络的训练过程。

## 权值初始化
### 0 值初始化 
在逻辑回归中，我们通常会初始化所有权值为0，假如在如下的神经网络也采用0值初始化：
![avatar](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/attachments/0%E5%80%BC%E5%88%9D%E5%A7%8B%E5%8C%96.png)
则可以得到：
$a_1^{(1)} = a_2^{(2)}$
则$\delta_1^{(1)} = \delta_2^{(1)}$
则$\frac{\partial}{\partial \Theta_{01}^{(1)}J(\Theta)}$ = $\frac{\partial}{\partial \Theta_{02}^{(1)}}J(\Theta)$
则更新后的权值：$\Theta_{01}^{(1)}$ = $\Theta_{02}^{(1)}$

亦即，每次迭代，所有权值的数值都一样，这意味着，隐含层的神经元激活值也将一样，也就是无论隐含层层数有多少，各层的神经元有多少，由于各层的神经元激活值大小一样，也就相当于各层只有一个有效神经元（特征），这就失去了神经网络进行特征扩展和优化的本意了。

### 随机初始化 
我们看到了固定值初始化将会是神经网络丧失其特性，因此，对于各层的权值矩阵，采用随机初始化策略。随机值产生的区间我们定义为$[-\epsilon, +\epsilon]$，并假定：
$\Theta^{(1)} \in R^{10 \times 11}, \Theta^{(2)} \in R^{1 \times 11}$
在python中，随机初始化权值的代码如下：
```python
import numpy as np

Theta1 = np.random.rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON
Theta2 = np.random.rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON
```




